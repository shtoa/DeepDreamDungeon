{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed203ee2-1b86-4b09-ad62-5c67ba6022c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fixes\n",
    "# pip install -U torch\n",
    "# pip install -U accelerate\n",
    "# pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "# pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "247830d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecb9ce9e-f232-42d9-86aa-30d420f8ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13ced245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "# See: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html#creating-models\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f8ffb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80e05ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matve\\anaconda3\\envs\\DMLCP\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Config of the audio_encoder: <class 'transformers.models.encodec.modeling_encodec.EncodecModel'> is overwritten by shared audio_encoder config: EncodecConfig {\n",
      "  \"_name_or_path\": \"facebook/encodec_32khz\",\n",
      "  \"architectures\": [\n",
      "    \"EncodecModel\"\n",
      "  ],\n",
      "  \"audio_channels\": 1,\n",
      "  \"chunk_length_s\": null,\n",
      "  \"codebook_dim\": 128,\n",
      "  \"codebook_size\": 2048,\n",
      "  \"compress\": 2,\n",
      "  \"dilation_growth_rate\": 2,\n",
      "  \"hidden_size\": 128,\n",
      "  \"kernel_size\": 7,\n",
      "  \"last_kernel_size\": 7,\n",
      "  \"model_type\": \"encodec\",\n",
      "  \"norm_type\": \"weight_norm\",\n",
      "  \"normalize\": false,\n",
      "  \"num_filters\": 64,\n",
      "  \"num_lstm_layers\": 2,\n",
      "  \"num_residual_layers\": 1,\n",
      "  \"overlap\": null,\n",
      "  \"pad_mode\": \"reflect\",\n",
      "  \"residual_kernel_size\": 3,\n",
      "  \"sampling_rate\": 32000,\n",
      "  \"target_bandwidths\": [\n",
      "    2.2\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"trim_right_ratio\": 1.0,\n",
      "  \"upsampling_ratios\": [\n",
      "    8,\n",
      "    5,\n",
      "    4,\n",
      "    4\n",
      "  ],\n",
      "  \"use_causal_conv\": false,\n",
      "  \"use_conv_shortcut\": false\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.musicgen.modeling_musicgen.MusicgenForCausalLM'> is overwritten by shared decoder config: MusicgenDecoderConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"audio_channels\": 1,\n",
      "  \"bos_token_id\": 2048,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"musicgen_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 4,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 2048,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2048\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "\n",
    "audioProcessor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "audioModel = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
    "audioModel = audioModel.to(device)\n",
    "sampling_rate = audioModel.config.audio_encoder.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97327c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from diffusers import StableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa02c0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 10.91it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"CompVis/stable-diffusion-v1-4\"\n",
    "# Check out other models by CompVis, different flavours: https://huggingface.co/CompVis\n",
    "# Runway also has a few: https://huggingface.co/runwayml, for instance \"runwayml/stable-diffusion-v1-5\"\n",
    "# or Stability AI (scroll down to models): https://huggingface.co/stabilityai?search_models=stable-diffusion\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    variant=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker = None # remove NSFW filter\n",
    ").to(device)\n",
    "\n",
    "# Note:  removing the filter is no licence to do harm, it is to give *you* the responsibility\n",
    "# of your use. (Also, the HF safety_checker is very, very conservative, and rejects\n",
    "# a lot of abstract images.)\n",
    "# (you can also do it later btw: pipe.safety_checker = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f718ae6-4b26-41a5-835e-546c4c589c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptResult():\n",
    "    def __init__(self):\n",
    "        self.prompt = None;\n",
    "        self.result = None;\n",
    "    \n",
    "class Room:\n",
    "    def __init__(self):\n",
    "        self.textures = {\n",
    "            \"floor\": PromptResult(),\n",
    "            \"ceiling\": PromptResult(),\n",
    "            \"wall\": PromptResult()\n",
    "        }\n",
    "        \n",
    "        self.sound = PromptResult();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5b117736-b678-4c84-9024-b74fb1cea716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chatgpt4\n",
    "# Generate a list of 10 themepark themes just names, python list\n",
    "\n",
    "themepark_themes = [\n",
    "    \"Mythical Realms Adventure\",\n",
    "    \"Time Traveler’s Paradise\",\n",
    "    \"Underwater Utopia\",\n",
    "    \"Galactic Odyssey\",\n",
    "    \"Enchanted Forest Escape\",\n",
    "    \"Steampunk City\",\n",
    "    \"Pirates and Privateers Cove\",\n",
    "    \"Candyland Kingdom\",\n",
    "    \"Wild West Frontier\",\n",
    "    \"Superhero Metropolis\",\n",
    "    \"Dinosaur Dominion\",\n",
    "    \"Haunted Hollow\",\n",
    "    \"Fantasy Kingdom\",\n",
    "    \"Arctic Expedition\",\n",
    "    \"Safari Wilderness\",\n",
    "    \"Musical Wonderland\"\n",
    "]\n",
    "\n",
    "# somehow generate multiple themes\n",
    "# maybe have function to extract theme and expand close words\n",
    "flatnessPrompt = \" 2D, Orthographic Projection, two-dimensional, flat view, flat lay\"\n",
    "stylePrompt = \" detailed, intricate, eccentric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5ba03c3d-83c6-487e-a195-a7e270ff10bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.88it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.26it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.25it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.01it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.25it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.20it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.10it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.28it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 21.83it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 21.91it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.20it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.02it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.04it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.17it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.23it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.15it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.10it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done generating\n"
     ]
    }
   ],
   "source": [
    "## use data set on pipelines\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# maybe rewrite using yield\n",
    "for theme in themepark_themes:\n",
    "    \n",
    "    newRoom = Room() \n",
    "\n",
    "    path = f'./themes/{theme}';\n",
    "    texturePath = f'{path}/textures';\n",
    "    \n",
    "    if(os.path.isdir(path) == False):\n",
    "    \n",
    "        os.mkdir(path);\n",
    "    \n",
    "    if(os.path.isdir(texturePath) == False):\n",
    "        \n",
    "        os.mkdir(texturePath);\n",
    "    \n",
    "        for key in newRoom.textures.keys():\n",
    "            \n",
    "            newRoom.textures[key].prompt = f'{key} texture in a {theme} themed themepark' + flatnessPrompt + stylePrompt;\n",
    "            newRoom.textures[key].result = pipe(newRoom.textures[key].prompt).images[0];\n",
    "    \n",
    "            newRoom.textures[key].result.save(f'{texturePath}/{key}.png');\n",
    "            #display(newRoom.textures[key].result);\n",
    "\n",
    "print(\"done generating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c623ea81-ded6-44a9-a90f-8fd0c2d794a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_sounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "32574f91-58a9-452d-a459-a4a24e98fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "\n",
    "def remove_images():\n",
    "\n",
    "    themes = glob.glob('./themes/*');\n",
    "    \n",
    "    for theme in themes:\n",
    "        if(os.path.isdir(theme+\"/textures\") == True):\n",
    "            shutil.rmtree(theme+\"/textures\");\n",
    "\n",
    "def remove_sounds():\n",
    "    themes = glob.glob('./themes/*');\n",
    "    \n",
    "    for theme in themes:\n",
    "        if(os.path.isdir(theme+\"/sounds\") == True):\n",
    "            shutil.rmtree(theme+\"/sounds\");\n",
    "\n",
    "def remove_all():\n",
    "    files = glob.glob('./themes/*')\n",
    "    for f in files:\n",
    "        shutil.rmtree(f);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0e51792b-22de-4db2-a813-245b51e4bc50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated\n",
      "Generated\n",
      "Generated\n",
      "Generated\n",
      "Generated\n",
      "Generated\n",
      "done generating\n"
     ]
    }
   ],
   "source": [
    "# 3 minutes\n",
    "\n",
    "import scipy.io.wavfile\n",
    "import os\n",
    "for theme in themepark_themes:\n",
    "    path = f'./themes/{theme}';\n",
    "    soundPath = f'./themes/{theme}/sounds'\n",
    "    \n",
    "    if(os.path.isdir(path) == False):\n",
    "        os.mkdir(path);\n",
    "    if(os.path.isdir(soundPath) == False):\n",
    "        os.mkdir(soundPath);\n",
    "        audioInputs = audioProcessor(\n",
    "            text=[f'loop for a {theme} themed themepark jingle'], # maybe have model convert to music genre or instruments\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        audioInputs.to(device)\n",
    "\n",
    "        audio_values = audioModel.generate(**audioInputs, max_new_tokens=1024) # generate 20 seconds\n",
    "        print(\"Generated\")\n",
    "        scipy.io.wavfile.write(f'{soundPath}/{theme}.wav', sampling_rate, np.array(audio_values.cpu().detach().numpy()));\n",
    "        #Audio(audio_values.cpu()[0], rate=sampling_rate) # figure out way to make it loopable\n",
    "print(\"done generating\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "82d780ff-8860-4caf-8d1e-45677241c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./themes/themes.txt', 'w') as f:\n",
    "    for theme in themepark_themes:\n",
    "        f.write(f\"{theme}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "48638982-03df-4bd7-bdb5-5a286386e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    themes = glob.glob('./website/themes/*')\n",
    "    \n",
    "    for theme in themes:\n",
    "    \n",
    "        if(os.path.isdir(theme+\"/textures\") == True):\n",
    "            files = glob.glob(theme+\"/textures/*\")\n",
    "            for f in files:\n",
    "                os.rename(f,os.path.relpath(f).replace(os.path.basename(f), \"\")+os.path.basename(f).replace(\"texture\",\"\"));\n",
    "\n",
    "        #     shutil.rmtree(theme+\"/textures\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
